{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQzBxfmDqVh/J0UaGNAHIb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/shopper_sentiments.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tjTcVg0FV461"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "!pip install gradio==3.14.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/nelgiriyewithana/shoppersentiments\")"
      ],
      "metadata": {
        "id": "5BPMjVGbV5Vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/shoppersentiments/TeePublic_review.csv\", encoding='latin1')"
      ],
      "metadata": {
        "id": "8HZQQXuyV5X3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "jR0pRF7SV5aZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "G23tD5n0myPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "JNyEVo7LmyRn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "id": "zTJyDF7ZmyUI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=df[['review','review-label']]"
      ],
      "metadata": {
        "id": "1ixglHKcmyWO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "k2GJr95DV5cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=data.dropna()"
      ],
      "metadata": {
        "id": "KwWzxbC6oOmW"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "6Ea6xOGAoOoa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['review-label'].value_counts()"
      ],
      "metadata": {
        "id": "Rozbontvp5Mf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and functions\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Bidirectional,GRU,Dropout,BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle\n",
        "import gradio as gr\n",
        "from keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "vhgqXBpVoWfs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define necessary objects\n",
        "precision_metric = Precision()\n",
        "stemmer=PorterStemmer()\n",
        "English_stopwords=stopwords.words('english')"
      ],
      "metadata": {
        "id": "8gVuFrvPoWh-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that process texts\n",
        "def text_cleaner(text):\n",
        "  text=text.lower()# Convert to lower cases\n",
        "  text_with_no_punctuations = re.sub(r'[^a-zA-Z0-9]', ' ', text) # Remove non alphabatic symbols\n",
        "  tokens=word_tokenize(text_with_no_punctuations) # tokeize words\n",
        "  stemmed_text = [stemmer.stem(word) for word in tokens] # Apply stemming\n",
        "  text = ' '.join(stemmed_text)\n",
        "  text_with_no_stopwords=[word for word in text.split() if word not in English_stopwords]# remove english stopwords\n",
        "  final_cleaned_text=' '.join(text_with_no_stopwords)\n",
        "  return final_cleaned_text"
      ],
      "metadata": {
        "id": "puiZq_sGpoiF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that returns the length of a text\n",
        "def count_words(text):\n",
        "  return len(text.split())"
      ],
      "metadata": {
        "id": "w9sDnWJJpokc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_review']=data['review'].apply(text_cleaner)"
      ],
      "metadata": {
        "id": "DYOkPikzpom3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_review_length']=data['cleaned_review'].apply(count_words)"
      ],
      "metadata": {
        "id": "bciebTIroWkD"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cleaned_review_length'].describe()"
      ],
      "metadata": {
        "id": "Q19Ikls4V5gh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tok=Tokenizer()\n",
        "Tok.fit_on_texts(data['cleaned_review'])\n",
        "vocab_size=len(Tok.word_index)+1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHXWZFbPrEt8",
        "outputId": "7f7f3570-a605-4fdf-ec83-5beb2f2bd390"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38028\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y=to_categorical(data['review-label'])\n",
        "x=Tok.texts_to_sequences(data['cleaned_review'])\n",
        "x_padded=pad_sequences(x,maxlen=20,padding='post',truncating='post')"
      ],
      "metadata": {
        "id": "8sL5hnZCr-xU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing parts\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_padded,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "vKmwYrwYsQF7"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save tokenizer to a file\n",
        "with open(\"shoppersentiments_tokenizer.pickle\", \"wb\") as f:\n",
        "    pickle.dump(Tok, f)"
      ],
      "metadata": {
        "id": "oZIVRoDQ6VzL"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=110, input_length=20))\n",
        "model.add(Bidirectional(LSTM(200,return_sequences=False)))\n",
        "model.add(Dense(256,activation=\"relu\"))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(45,activation=\"relu\"))\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(6,activation='softmax'))\n"
      ],
      "metadata": {
        "id": "_Elcb0_RrEwi"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a checkpoint callback to save the best\n",
        "adam=Adam(learning_rate=0.0001)\n",
        "# Compile and train the model on training dataset over 8 epochs\n",
        "model.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['acc',precision_metric])\n",
        "history=model.fit(x_train,y_train,validation_split=0.2,epochs=8,batch_size=64)"
      ],
      "metadata": {
        "id": "FHamyDYlrEyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on testing dataset\n",
        "model.evaluate(x_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mzlECv3sC5sS",
        "outputId": "e4ab97a1-dc81-4999-c50e-f40911681650"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1548/1548 [==============================] - 46s 29ms/step - loss: 0.5728 - acc: 0.8013 - precision: 0.8586\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5728018879890442, 0.8012722134590149, 0.8586050271987915]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as HDF5 file\n",
        "model.save(\"shopper_sentiment_model.h5\")"
      ],
      "metadata": {
        "id": "IvDSCEBkDBdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for demo\n",
        "def review_rating(text):\n",
        "  # clean the input text\n",
        "    cleaned_text = text_cleaner(text)\n",
        "  # convert the cleaned text to a sequence of integers\n",
        "    text_array = Tok.texts_to_sequences([cleaned_text])\n",
        "  # pad the sequence\n",
        "    padded_array = pad_sequences(text_array, maxlen=20, padding='post', truncating='post')\n",
        "  # use the model created to generate predictions\n",
        "    prediction = model.predict(padded_array)\n",
        "\n",
        "    # Find the predicted class\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    return predicted_class"
      ],
      "metadata": {
        "id": "lwML9dVxDBfv"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 2\n",
        "review_rating(\"Very bad and cold tee\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hgyb7LIqDBin",
        "outputId": "02559f63-c4ae-48c2-cdc7-d68b21f27341"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 829ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 2\n",
        "review_rating(\"These guys offer the best customer service in the city!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MlpYz2FC7Fy",
        "outputId": "a739c2d3-493d-4be2-b44d-51555871f13c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio interface\n",
        "iface = gr.Interface(\n",
        "    fn=review_rating,\n",
        "    inputs=gr.inputs.Textbox(lines=5, label=\"Enter your text here\"),\n",
        "    outputs=gr.outputs.Label(num_top_classes=6),\n",
        "    title=\"Sentiment Analysis\",\n",
        "    description=\"Enter a text and the model will predict the level of satisfication.\"\n",
        ")\n",
        "# Launch the interface\n",
        "iface.launch(debug='True')"
      ],
      "metadata": {
        "id": "rlfvLqmMrE1W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}