{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrn/OEqzGYP2BndmEYikRr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/alzheimer_mri_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JYJmsTMpAwvU"
      },
      "outputs": [],
      "source": [
        "# Install opendatasets library\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gradio library\n",
        "!pip install gradio==3.14.0"
      ],
      "metadata": {
        "id": "yVKVKCY-Wt0N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and functions\n",
        "from tensorflow.keras.layers import MaxPooling2D,Dense,Flatten,Conv2D,Input,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import opendatasets as od\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import shutil\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yrvSk3yohQZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the dataset from kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/sachinkumar413/alzheimer-mri-dataset\")"
      ],
      "metadata": {
        "id": "V95RnQ3KAxuG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED=42#randomseed=42"
      ],
      "metadata": {
        "id": "GbKp1-BrGqOU"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Mild_Demented_path=\"/content/alzheimer-mri-dataset/Dataset/Mild_Demented\"\n",
        "Moderate_Demented_path=\"/content/alzheimer-mri-dataset/Dataset/Moderate_Demented\"\n",
        "Very_Mild_Demented_path=\"/content/alzheimer-mri-dataset/Dataset/Very_Mild_Demented\"\n",
        "# Create Demented directory\n",
        "Demented_path=os.path.join(\"/content/alzheimer-mri-dataset/Dataset\",\"Demented\")\n",
        "os.makedirs(Demented_path,exist_ok=True)\n",
        "# Set the list for each class\n",
        "mild_demented_images=list(os.listdir(Mild_Demented_path))\n",
        "moderate_demented_images=list(os.listdir(Moderate_Demented_path))\n",
        "very_demented_images=list(os.listdir(Very_Mild_Demented_path))"
      ],
      "metadata": {
        "id": "cZDKlzZYAxwl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image in mild_demented_images:\n",
        "  source_path=os.path.join(Mild_Demented_path,image)\n",
        "  destination_path=os.path.join(Demented_path,image)\n",
        "  shutil.move(source_path,destination_path)\n",
        "for image in moderate_demented_images:\n",
        "  source_path=os.path.join(Moderate_Demented_path,image)\n",
        "  destination_path=os.path.join(Demented_path,image)\n",
        "  shutil.move(source_path,destination_path)\n",
        "for image in very_demented_images:\n",
        "  source_path=os.path.join(Very_Mild_Demented_path,image)\n",
        "  destination_path=os.path.join(Demented_path,image)\n",
        "  shutil.move(source_path,destination_path)"
      ],
      "metadata": {
        "id": "hzJjdhW8Axzb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes=['Demented','Non_Demented']\n",
        "for class_name in classes:\n",
        " train_dir=os.path.join(\"/content/alzheimer-mri-dataset/Dataset\",\"train\",class_name)\n",
        " os.makedirs(train_dir,exist_ok=True)\n",
        " valid_dir=os.path.join(\"/content/alzheimer-mri-dataset/Dataset\",\"valid\",class_name)\n",
        " os.makedirs(valid_dir,exist_ok=True)\n",
        "from sklearn.model_selection import train_test_split\n",
        "demented_train_images,demented_valid_images=train_test_split(\n",
        "    list(os.listdir(\"/content/alzheimer-mri-dataset/Dataset/Demented\")),test_size=0.2)\n",
        "non_demented_train_images,non_demented_valid_images=train_test_split(\n",
        "    list(os.listdir(\"/content/alzheimer-mri-dataset/Dataset/Non_Demented\")),test_size=0.2)\n",
        "for image,img in zip(demented_train_images,demented_valid_images):\n",
        "  source_path_1=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/Demented\",image)\n",
        "  destination_path_1=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/train/Demented\",image)\n",
        "  shutil.move(source_path_1,destination_path_1)\n",
        "  source_path_2=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/Demented\",img)\n",
        "  destination_path_2=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/valid/Demented\",img)\n",
        "  shutil.move(source_path_2,destination_path_2)\n"
      ],
      "metadata": {
        "id": "iRsqus3EAx6u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for image,img in zip(non_demented_train_images,non_demented_valid_images):\n",
        "  source_path_1=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/Non_Demented\",image)\n",
        "  destination_path_1=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/train/Non_Demented\",image)\n",
        "  shutil.move(source_path_1,destination_path_1)\n",
        "  source_path_2=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/Non_Demented\",img)\n",
        "  destination_path_2=os.path.join(\"/content/alzheimer-mri-dataset/Dataset/valid/Non_Demented\",img)\n",
        "  shutil.move(source_path_2,destination_path_2)"
      ],
      "metadata": {
        "id": "QC9w_dlRGJRN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the parameters for data augmentation and preprocessing\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Rescale pixel values to [0, 1]\n",
        "    rotation_range=15,  # Rotate images randomly by up to 15 degrees\n",
        "    width_shift_range=0.1,  # Shift images horizontally by up to 10% of the width\n",
        "    height_shift_range=0.1,  # Shift images vertically by up to 10% of the height\n",
        "    shear_range=0.1,  # Shear transformations with a maximum shear intensity of 10%\n",
        "    zoom_range=0.1,  # Zoom in randomly by up to 10%\n",
        "    horizontal_flip=True,  # Flip images horizontally\n",
        "    vertical_flip=True,  # Flip images vertically\n",
        "    fill_mode='nearest'  # Fill missing pixels using the nearest value\n",
        ")\n",
        "\n",
        "# Define the directory containing your image data\n",
        "train_dir = \"/content/alzheimer-mri-dataset/Dataset/train\"\n",
        "valid_dir= \"/content/alzheimer-mri-dataset/Dataset/valid\"\n",
        "\n",
        "# Create an ImageDataGenerator for the training data\n",
        "train_generator =datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n",
        "\n",
        "valid_generator=datagen.flow_from_directory(\n",
        "    valid_dir,\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")\n"
      ],
      "metadata": {
        "id": "dCOB7L8LGJTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape\n",
        "input_shape = (256, 256, 3)  #  Input images are 256x256 RGB images\n",
        "\n",
        "# Define input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Convolutional layers\n",
        "layer_1= Conv2D(12, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "layer_2 =MaxPooling2D(pool_size=(2, 2))(layer_1)\n",
        "layer_3 = Conv2D(24, kernel_size=(3, 3), activation='relu')(layer_2)\n",
        "layer_4 = MaxPooling2D(pool_size=(2, 2))(layer_3)\n",
        "\n",
        "# Flatten layer\n",
        "layer_5= Flatten()(layer_4)\n",
        "\n",
        "# Dense layers\n",
        "layer_6 = Dense(100, activation='relu')(layer_5)\n",
        "outputs = Dense(1, activation='sigmoid')(layer_6)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',Precision()])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPykaau3Ax9E",
        "outputId": "e42e08bc-0853-4f68-b2ca-062250ed2f25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 254, 254, 12)      336       \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPoolin  (None, 127, 127, 12)      0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 125, 125, 24)      2616      \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPoolin  (None, 62, 62, 24)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 92256)             0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 100)               9225700   \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9228753 (35.20 MB)\n",
            "Trainable params: 9228753 (35.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a checkpoint callback to save the best\n",
        "checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "# Train your model with the callback\n",
        "history=model.fit(train_generator,validation_data=(valid_generator),epochs=30,batch_size=len(train_generator),callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "9QXeK5i8MScm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights into your model\n",
        "model.load_weights('best_weights.h5')"
      ],
      "metadata": {
        "id": "UdEFbXZHeu2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on valid_generator\n",
        "model.evaluate(valid_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wExjlEbNMSfP",
        "outputId": "f4c63c92-f735-439c-ad84-2215dae56c6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 22s 535ms/step - loss: 0.5786 - accuracy: 0.7039 - precision_3: 0.7310\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5786424279212952, 0.703906238079071, 0.7309734225273132]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `history.history` is a dictionary containing the training and validation metrics\n",
        "# Plotting accuracy\n",
        "plt.subplot(2, 1, 1)  # 2 rows, 1 column, plot 1 (top subplot)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plotting precision\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2 (bottom subplot)\n",
        "plt.plot(history.history['precision_3'])\n",
        "plt.plot(history.history['val_precision_3'])\n",
        "plt.title('Model Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()  # Adjust subplot layout to avoid overlap\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JUBF9B02MSh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as an HDF5 file\n",
        "model.save('alzheimer_mri_model.h5')"
      ],
      "metadata": {
        "id": "dph7rkRWMSkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MobileNetV1 base model without top (fully connected) layers\n",
        "#base_model = MobileNet(weights='imagenet', include_top=False)\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the MobileNetV1 base model to the Sequential model\n",
        "model.add(base_model)\n",
        "# Set MobileNetV1 layers as non-trainable\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Add custom dense layers for classification\n",
        "model.add(Dense(220, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "id": "y6VY3nLxMSmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',Precision()])\n",
        "# Define a checkpoint callback to save the best\n",
        "checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "# Train the model\n",
        "history=model.fit(train_generator,validation_data=(valid_generator),epochs=15,batch_size=len(train_generator),callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "yjZH4ps-VxoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# `history.history` is a dictionary containing the training and validation metrics\n",
        "# Plotting accuracy\n",
        "plt.subplot(2, 1, 1)  # 2 rows, 1 column, plot 1 (top subplot)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plotting precision\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2 (bottom subplot)\n",
        "plt.plot(history.history['precision_3'])\n",
        "plt.plot(history.history['val_precision_3'])\n",
        "plt.title('Model Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()  # Adjust subplot layout to avoid overlap\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "SLcL0osuhMtZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights into your model(second model has better performance over unseen data)\n",
        "model.load_weights('best_weights.h5')"
      ],
      "metadata": {
        "id": "H74_h63ZVxqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the second model\n",
        "model.save(\"alzheimer_model_2.h5\")"
      ],
      "metadata": {
        "id": "2sKGL-QvAx_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the second model\n",
        "model=load_model(\"/content/alzheimer_model_2.h5\")"
      ],
      "metadata": {
        "id": "lhIdybPJdseA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the second model on valid_generator\n",
        "model.evaluate(valid_generator)"
      ],
      "metadata": {
        "id": "PsDB8s-QVxsu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a697638-df5f-4c44-9fd9-6c7c1417add8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40/40 [==============================] - 91s 2s/step - loss: 0.5019 - accuracy: 0.7516 - precision_1: 0.7738\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5018686652183533, 0.7515624761581421, 0.773809552192688]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnosis(img_path):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = model.predict(img_array)\n",
        "    #return prediction\n",
        "    # Check if prediction is positive or negative\n",
        "    if prediction <= 0.5:\n",
        "        return 'Tumor presence: positive.'\n",
        "    else:\n",
        "        return 'Tumor presence: negative.'\n",
        "\n"
      ],
      "metadata": {
        "id": "KRrff5-vWt5T"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 1\n",
        "img=\"/content/alzheimer-mri-dataset/Dataset/train/Demented/mild_106.jpg\"\n",
        "diagnosis(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "-2EI4dZIfqeb",
        "outputId": "f14a686c-32ef-49b2-aff3-411a036126d9"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 66ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tumor presence: positive.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 2\n",
        "img=\"/content/alzheimer-mri-dataset/Dataset/train/Non_Demented/non_10.jpg\"\n",
        "diagnosis(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "_erRSxg8oELS",
        "outputId": "005d6b4b-3834-4ec8-b8e1-e07772a40a36"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 54ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tumor presence: negative.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function suitable for gradio\n",
        "def gradio_fn(img_array):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.fromarray(np.uint8(img_array))\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Check if prediction is positive or negative\n",
        "    if prediction <= 0.5:\n",
        "        return 'Tumor presence: positive.'\n",
        "    else:\n",
        "        return 'Tumor presence: negative.'"
      ],
      "metadata": {
        "id": "zQP06h4RgTXd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input component for the Gradio interface\n",
        "inputs = gr.inputs.Image(shape=(224, 224))\n",
        "\n",
        "# Define the output component for the Gradio interface\n",
        "outputs = gr.outputs.Label()\n",
        "\n",
        "# Create the Gradio interface\n",
        "gr.Interface(gradio_fn, inputs, outputs, capture_session=True,share=True).launch(debug='True')"
      ],
      "metadata": {
        "id": "2rEJv2YLeHrS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}