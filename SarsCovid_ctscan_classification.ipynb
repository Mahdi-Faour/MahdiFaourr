{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMMdb9zR2XtOffh2j/6LGcr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/SarsCovid_ctscan_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52KhDr1PssVp"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.14.0"
      ],
      "metadata": {
        "id": "ZktI5pD1vj_C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense,Flatten,MaxPooling2D,Input,Conv2D\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "px25WlQ1vmt-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from Kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/plameneduardo/sarscov2-ctscan-dataset?select=COVID\")"
      ],
      "metadata": {
        "id": "i_to_NbDvjiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "root_dir=\"/content/sarscov2-ctscan-dataset\"\n",
        "classes=['COVID','non-COVID']\n",
        "for class_name in classes:\n",
        "  train_dir=os.path.join(root_dir,\"train\",class_name)\n",
        "  os.makedirs(train_dir,exist_ok=True)\n",
        "  valid_dir=os.path.join(root_dir,\"valid\",class_name)\n",
        "  os.makedirs(valid_dir,exist_ok=True)\n",
        "COVID_images=list(os.listdir(os.path.join(root_dir,\"COVID\")))\n",
        "non_COVID_images=list(os.listdir(os.path.join(root_dir,\"non-COVID\")))"
      ],
      "metadata": {
        "id": "khGMF81Xvjld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "covid_train_images,covid_valid_images=train_test_split(COVID_images,test_size=0.1,random_state=42)\n",
        "for img in covid_train_images:\n",
        "  source_path_1=os.path.join(root_dir,'COVID',img)\n",
        "  destination_path_1=os.path.join(root_dir,'train','COVID',img)\n",
        "  shutil.move(source_path_1,destination_path_1)\n",
        "for image in covid_valid_images:\n",
        "  source_path_2=os.path.join(root_dir,'COVID',image)\n",
        "  destination_path_2=os.path.join(root_dir,'valid','COVID',image)\n",
        "  shutil.move(source_path_2,destination_path_2)"
      ],
      "metadata": {
        "id": "0n0XP8Oj21W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_covid_train_images,non_covid_valid_images=train_test_split(non_COVID_images,test_size=0.1,random_state=42)\n",
        "for img in non_covid_train_images:\n",
        "  source_path_1=os.path.join(root_dir,'non-COVID',img)\n",
        "  destination_path_1=os.path.join(root_dir,'train','non-COVID',img)\n",
        "  shutil.move(source_path_1,destination_path_1)\n",
        "for image in non_covid_valid_images:\n",
        "  source_path_2=os.path.join(root_dir,'non-COVID',image)\n",
        "  destination_path_2=os.path.join(root_dir,'valid','non-COVID',image)\n",
        "  shutil.move(source_path_2,destination_path_2)\n"
      ],
      "metadata": {
        "id": "a1XmHfj2vjoJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the data generator and specify preprocessing/augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=False,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Create a generator for training data\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    \"/content/sarscov2-ctscan-dataset/train\",\n",
        "    batch_size=32,\n",
        "    class_mode='binary')\n",
        "\n",
        "# Create a generator for validation data (optional)\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    \"/content/sarscov2-ctscan-dataset/valid\",\n",
        "    batch_size=32,\n",
        "    class_mode='binary'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF_CR6mcvjqq",
        "outputId": "02a428e3-2f02-4ac3-fe95-c9bf0258b34a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2232 images belonging to 2 classes.\n",
            "Found 249 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input shape\n",
        "input_shape = (256, 256, 3)  #  Input images are 256x256 RGB images\n",
        "\n",
        "# Define input layer\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Convolutional layers\n",
        "layer_1= Conv2D(12, kernel_size=(3, 3), activation='relu')(inputs)\n",
        "layer_2 =MaxPooling2D(pool_size=(2, 2))(layer_1)\n",
        "layer_3 = Conv2D(24, kernel_size=(3, 3), activation='relu')(layer_2)\n",
        "layer_4 = MaxPooling2D(pool_size=(2, 2))(layer_3)\n",
        "\n",
        "# Flatten layer\n",
        "layer_5= Flatten()(layer_4)\n",
        "\n",
        "# Dense layers\n",
        "layer_6 = Dense(100, activation='relu')(layer_5)\n",
        "outputs = Dense(1, activation='sigmoid')(layer_6)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy',Precision()])\n",
        "\n",
        "# Print model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mr0gXPsrCYVq",
        "outputId": "2ab641b0-7829-45f2-d008-76fe594f44ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 256, 256, 3)]     0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 254, 254, 12)      336       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 127, 127, 12)      0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 125, 125, 24)      2616      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 62, 62, 24)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 92256)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               9225700   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9228753 (35.20 MB)\n",
            "Trainable params: 9228753 (35.20 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a checkpoint callback to save the best\n",
        "checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "# Train your model with the callback\n",
        "history=model.fit(train_generator,validation_data=(validation_generator),epochs=30,batch_size=len(train_generator),callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "s719fTXDCYdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights into your model\n",
        "model.load_weights('best_weights.h5')"
      ],
      "metadata": {
        "id": "qN1Q1F6CCYgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on valid_generator\n",
        "model.evaluate(validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_XW_RXCfjjX",
        "outputId": "dcfe6766-57f7-4c0c-9894-af7f658c4f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8/8 [==============================] - 8s 966ms/step - loss: 0.3760 - accuracy: 0.8434 - precision: 0.8443\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.37595340609550476, 0.8433734774589539, 0.8442623019218445]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# `history.history` is a dictionary containing the training and validation metrics\n",
        "# Plotting accuracy\n",
        "plt.subplot(2, 1, 1)  # 2 rows, 1 column, plot 1 (top subplot)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plotting precision\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2 (bottom subplot)\n",
        "plt.plot(history.history['precision'])\n",
        "plt.plot(history.history['val_precision'])\n",
        "plt.title('Model Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()  # Adjust subplot layout to avoid overlap\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ms-b5tTFfjmp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as an HDF5 file\n",
        "model.save('sarascov2_ctscan_model.h5')"
      ],
      "metadata": {
        "id": "OOFxzocef_Tp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnosis(img_path):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((256, 256))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = model.predict(img_array)\n",
        "    #return prediction\n",
        "    # Check if prediction is positive or negative\n",
        "    if prediction <= 0.5:\n",
        "        return 'Covid Presence: positive.'\n",
        "    else:\n",
        "        return 'Covid Presence: negative.'\n"
      ],
      "metadata": {
        "id": "7ip4C0waf_WA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 1\n",
        "image=\"/content/sarscov2-ctscan-dataset/valid/non-COVID/Non-Covid (2).png\"\n",
        "diagnosis(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JDGGkAbAhIva",
        "outputId": "33a0fd30-018e-43d8-f8ba-5c854882bbc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 36ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Covid Presence: negative.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 2\n",
        "image=\"/content/sarscov2-ctscan-dataset/valid/non-COVID/Non-Covid (562).png\"\n",
        "diagnosis(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "YpjxuAwbid0j",
        "outputId": "7af4701e-9d58-49d5-eb98-9dbd33457ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 60ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Covid Presence: negative.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 3\n",
        "image=\"/content/sarscov2-ctscan-dataset/valid/COVID/Covid (1137).png\"\n",
        "diagnosis(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "53NfsPeIid3T",
        "outputId": "4cdd707a-dc95-4fcc-82a9-05e757cf254f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Covid Presence: positive.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 4\n",
        "image='/content/sarscov2-ctscan-dataset/valid/COVID/Covid (344).png'\n",
        "diagnosis(image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "Oq9ut7Kjid6L",
        "outputId": "6094c924-a0a8-47dd-e955-a16fec98aa32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 142ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Covid Presence: positive.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function suitable for gradio\n",
        "def gradio_fn(img_array):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.fromarray(np.uint8(img_array))\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((256, 256))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Check if prediction is positive or negative\n",
        "    if prediction <= 0.5:\n",
        "        return 'Tumor presence: positive.'\n",
        "    else:\n",
        "        return 'Tumor presence: negative.'"
      ],
      "metadata": {
        "id": "IfIb_1HNzG1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input component for the Gradio interface\n",
        "inputs = gr.inputs.Image(shape=(256, 256))\n",
        "\n",
        "# Define the output component for the Gradio interface\n",
        "outputs = gr.outputs.Label()\n",
        "\n",
        "# Create the Gradio interface\n",
        "gr.Interface(gradio_fn, inputs, outputs, capture_session=True,share=True).launch(debug='True')"
      ],
      "metadata": {
        "id": "gvlSPzwEzG4Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}