{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPUb4Lg2ad8/g7JwAWs2OCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/Cyberbullying_detection_problem.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install opendatasets library\n",
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "BuikE-v7laIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and functions\n",
        "import pandas as pd\n",
        "import opendatasets as od\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,Dense,Embedding,Bidirectional\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ],
      "metadata": {
        "id": "Q4BUF7CRGf7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the opendatasets library to interact with kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/andrewmvd/cyberbullying-classification\")"
      ],
      "metadata": {
        "id": "vN9hbCaolaL2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data in pandas frame\n",
        "data=pd.read_csv(\"/content/cyberbullying-classification/cyberbullying_tweets.csv\")"
      ],
      "metadata": {
        "id": "rbdY-PPblaT9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "3leSLDxalaXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "v8e8AGbOGfjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cyberbullying_type'].value_counts()"
      ],
      "metadata": {
        "id": "yjwJLupHIBxy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check nulls\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "Cq3STtqNGfpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the cyberbullying_type column\n",
        "encoder=LabelEncoder()\n",
        "data['cyberbullying_type']=encoder.fit_transform(data['cyberbullying_type'])"
      ],
      "metadata": {
        "id": "jD5oH9iGGfsP"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display some samples from the data\n",
        "data.head()"
      ],
      "metadata": {
        "id": "O1YSOKd0Gfuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['cyberbullying_type'].value_counts()"
      ],
      "metadata": {
        "id": "hu3NYLIqGfyO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define necessary objects\n",
        "precision_metric = Precision()\n",
        "stemmer=PorterStemmer()\n",
        "English_stopwords=stopwords.words('english')"
      ],
      "metadata": {
        "id": "d4mA5kp0Gf1l"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that process texts\n",
        "def text_cleaner(text):\n",
        "  text=text.lower()# Convert to lower cases\n",
        "  text_with_no_punctuations = re.sub(r'[^a-zA-Z0-9]', ' ', text) # Remove non alphabatic symbols\n",
        "  tokens=word_tokenize(text_with_no_punctuations) # tokeize words\n",
        "  stemmed_text = [stemmer.stem(word) for word in tokens] # Apply stemming\n",
        "  text = ' '.join(stemmed_text)\n",
        "  text_with_no_stopwords=[word for word in text.split() if word not in English_stopwords]# remove english stopwords\n",
        "  final_cleaned_text=' '.join(text_with_no_stopwords)\n",
        "  return final_cleaned_text\n"
      ],
      "metadata": {
        "id": "pkVQ3O9LJORD"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Apply text_cleaner on tweets column\n",
        "data['cleaned_tweet']=data['tweet_text'].apply(text_cleaner)"
      ],
      "metadata": {
        "id": "zUn1OUucJOWD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function that returns the length of a text\n",
        "def count_words(text):\n",
        "  return len(text.split())"
      ],
      "metadata": {
        "id": "ASkBU2OIJOby"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply text_cleaner on cleaned_tweet column\n",
        "data['cleaned_tweet_length']=data['cleaned_tweet'].apply(count_words)"
      ],
      "metadata": {
        "id": "sZtBcHX0JOYv"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get some statistics for the cleaned_tweet_length column\n",
        "data['cleaned_tweet_length'].describe()"
      ],
      "metadata": {
        "id": "GPDYnwAwj-qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the tokenizer object\n",
        "tok=Tokenizer()\n",
        "tok.fit_on_texts(data['cleaned_tweet'])"
      ],
      "metadata": {
        "id": "vltCvfSdJoIT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the vocab_size\n",
        "vocab_size=len(tok.word_index)+1\n",
        "print(vocab_size)"
      ],
      "metadata": {
        "id": "FzZEiggHJoMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Define the features and the labels (in array formats)\n",
        "x=tok.texts_to_sequences(data['cleaned_tweet'])\n",
        "y=to_categorical(data['cyberbullying_type'])\n",
        "x_padded=pad_sequences(x,maxlen=40,padding='post',truncating='post')"
      ],
      "metadata": {
        "id": "Hh1oFspkJoPX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model\n",
        "model=Sequential()\n",
        "model=Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=50, input_length=40))\n",
        "model.add(Bidirectional(LSTM(120,return_sequences=False)))\n",
        "model.add(Dense(200,activation='relu'))\n",
        "model.add(Dense(45,activation='relu'))\n",
        "model.add(Dense(6,activation='softmax'))"
      ],
      "metadata": {
        "id": "EDJiHO4xJoRb"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and fit the data into the model\n",
        "model.compile(optimizer=\"adam\",loss=\"categorical_crossentropy\",metrics=[\"acc\",precision_metric])\n",
        "model.fit(x_padded,y,validation_split=0.1,batch_size=64,epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k7quc7IeLV-k",
        "outputId": "076767d9-79a6-4ff0-e6fc-e353710b2cd4"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "671/671 [==============================] - 124s 177ms/step - loss: 0.6389 - acc: 0.7244 - precision: 0.8615 - val_loss: 0.1651 - val_acc: 0.9642 - val_precision: 0.9747\n",
            "Epoch 2/10\n",
            "671/671 [==============================] - 126s 187ms/step - loss: 0.3335 - acc: 0.8675 - precision: 0.8818 - val_loss: 0.2994 - val_acc: 0.9329 - val_precision: 0.9468\n",
            "Epoch 3/10\n",
            "671/671 [==============================] - 123s 183ms/step - loss: 0.2358 - acc: 0.9062 - precision: 0.9128 - val_loss: 0.2158 - val_acc: 0.9589 - val_precision: 0.9621\n",
            "Epoch 4/10\n",
            "671/671 [==============================] - 118s 175ms/step - loss: 0.1815 - acc: 0.9237 - precision: 0.9271 - val_loss: 0.2796 - val_acc: 0.9400 - val_precision: 0.9460\n",
            "Epoch 5/10\n",
            "671/671 [==============================] - 120s 179ms/step - loss: 0.1537 - acc: 0.9304 - precision: 0.9331 - val_loss: 0.2380 - val_acc: 0.9553 - val_precision: 0.9577\n",
            "Epoch 6/10\n",
            "671/671 [==============================] - 117s 175ms/step - loss: 0.1339 - acc: 0.9367 - precision: 0.9389 - val_loss: 0.3042 - val_acc: 0.9434 - val_precision: 0.9457\n",
            "Epoch 7/10\n",
            "671/671 [==============================] - 122s 182ms/step - loss: 0.1158 - acc: 0.9423 - precision: 0.9446 - val_loss: 0.3107 - val_acc: 0.9413 - val_precision: 0.9444\n",
            "Epoch 8/10\n",
            "671/671 [==============================] - 121s 181ms/step - loss: 0.1090 - acc: 0.9456 - precision: 0.9471 - val_loss: 0.2983 - val_acc: 0.9447 - val_precision: 0.9468\n",
            "Epoch 9/10\n",
            "671/671 [==============================] - 120s 179ms/step - loss: 0.1037 - acc: 0.9454 - precision: 0.9470 - val_loss: 0.3134 - val_acc: 0.9386 - val_precision: 0.9417\n",
            "Epoch 10/10\n",
            "671/671 [==============================] - 120s 179ms/step - loss: 0.0946 - acc: 0.9466 - precision: 0.9486 - val_loss: 0.3077 - val_acc: 0.9507 - val_precision: 0.9535\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x79f882d7d300>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function for demo\n",
        "def cyberbullying_detector(text):\n",
        "  # clean the input text\n",
        "    cleaned_text = text_cleaner(text)\n",
        "  # convert the cleaned text to a sequence of integers\n",
        "    text_array = tok.texts_to_sequences([cleaned_text])\n",
        "  # pad the sequence\n",
        "    padded_array = pad_sequences(text_array, maxlen=40, padding='post', truncating='post')\n",
        "  # use the model created to generate predictions\n",
        "    prediction = model.predict(padded_array)\n",
        "\n",
        "    # Find the predicted class\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    if predicted_class==0:\n",
        "      print(\"Age-cyberbullying detected.\")\n",
        "    elif predicted_class==1:\n",
        "      print(\"Ethnicity-cyberbullying detected.\")\n",
        "    elif predicted_class==2:\n",
        "      print('Gender-cyberbullying detected.')\n",
        "    elif predicted_class==3:\n",
        "      print(\"No cyberbullying detected.\")\n",
        "    elif predicted_class==4:\n",
        "      print(\"Cyberbullying detected.\")\n",
        "    else:\n",
        "      print(\"Religion-cyvberbullying detected.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "P3ChY3xYZGEC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'am so Sorry, I do not admit the following speech! just manipulating examples from  real world to test my model\n",
        "text=\" Females are very stupid beings.\"\n",
        "cyberbullying_detector(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EtFuNXLyZGGx",
        "outputId": "7813b8a3-6c6e-45b8-87e1-9608a6486d21"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 2s 2s/step\n",
            "Gender-cyberbullying detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text=\"Hello Reader, How is your day going so far ?.\"\n",
        "cyberbullying_detector(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ROqOoSMdi43",
        "outputId": "bfa1a88d-3c0a-4a99-9772-ccd8bcdd5c4f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 30ms/step\n",
            "No cyberbullying detected.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model archi and weights\n",
        "model.save(\"model_cyberbullying.h5\")"
      ],
      "metadata": {
        "id": "BtTGYExYiTnM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}