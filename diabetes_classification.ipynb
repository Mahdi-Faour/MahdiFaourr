{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMpB9Sw25DtysUEb5sE8TE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/diabetes_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XWQHxUty2dF-"
      },
      "outputs": [],
      "source": [
        "# Install opendatasets library\n",
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary functions and libraries\n",
        "import opendatasets as od\n",
        "import pandas as pd\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier\n",
        "from sklearn.model_selection import cross_validate\n",
        "import numpy as np\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "oC_jMKkvB1ah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the data from kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/kandij/diabetes-dataset\")"
      ],
      "metadata": {
        "id": "jrLL4ltA2f4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the data in a pandas dataframe\n",
        "data=pd.read_csv(\"/content/diabetes-dataset/diabetes2.csv\")"
      ],
      "metadata": {
        "id": "KNNzu9PN2f7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a subpart of the data\n",
        "data.head()"
      ],
      "metadata": {
        "id": "soOfK87V2f9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data shape\n",
        "data.shape"
      ],
      "metadata": {
        "id": "ls5GaQ2y2f__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Search for nulls\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "ggmM6_cA2gCo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data info\n",
        "data.info()"
      ],
      "metadata": {
        "id": "clgyRms42gFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create two sub datas each one contains a class from the Outcome column\n",
        "data_positive=data[data['Outcome']==0]\n",
        "data_negative=data[data['Outcome']==1]"
      ],
      "metadata": {
        "id": "qroVHyye3ll2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram for each column in data_positive\n",
        "for column in data_positive.columns:\n",
        "  if column!='Outcome':\n",
        "    plt.figure()  # Create a new figure for each histogram\n",
        "    data_positive[column].hist()\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show\n"
      ],
      "metadata": {
        "id": "9Vw7fnAW3lqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot a histogram for each column in data_negative\n",
        "for column in data_negative.columns:\n",
        "  if column!='Outcome':\n",
        "    plt.figure()  # Create a new figure for each histogram\n",
        "    data_negative[column].hist()\n",
        "    plt.title(f'Histogram of {column}')\n",
        "    plt.xlabel(column)\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.grid(True)\n",
        "    plt.show"
      ],
      "metadata": {
        "id": "0BIIimhI2gKb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalize the data\n",
        "data_max=data.max()\n",
        "data=data.divide(data_max)"
      ],
      "metadata": {
        "id": "o6I2FigfAS5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check classes distribution in Outcome column\n",
        "data['Outcome'].value_counts()"
      ],
      "metadata": {
        "id": "WdEfILkJfFKh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Over sample the minor class\n",
        "x=data.drop(['Outcome'],axis=1).values\n",
        "y=data['Outcome'].values\n",
        "over=RandomOverSampler(sampling_strategy=0.9)\n",
        "x_new,y_new=over.fit_resample(x,y)\n",
        "# Split the data into training and testing parts\n",
        "x_train,x_test,y_train,y_test=train_test_split(x_new,y_new,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "a4ZFfG8efdYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize some classical models\n",
        "Lr=LogisticRegression()\n",
        "sv=SVC()\n",
        "tree=DecisionTreeClassifier()\n",
        "forest=RandomForestClassifier()\n",
        "adab=AdaBoostClassifier()\n"
      ],
      "metadata": {
        "id": "5nmSwvPYfFHp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Iterate over the models and perform cross validation for each one\n",
        "models=[Lr,sv,tree,forest,adab]\n",
        "for model in models:\n",
        "  result=cross_validate(model,x_train,y_train,cv=3,scoring=['accuracy','precision','recall'])\n",
        "  print(f'{model}')\n",
        "  print(\"Accuracy %:\", np.mean(result['test_accuracy'])*100)\n",
        "  print(\"Precision %:\", np.mean(result['test_accuracy'])*100)\n",
        "  print(\"Recall %:\", np.mean(result['test_accuracy'])*100)\n",
        "  print(\"----------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKaALe9UhE__",
        "outputId": "5489d093-a198-44c2-efcb-c8f7f19a9001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression()\n",
            "Accuracy %: 76.04909070160697\n",
            "Precision %: 76.04909070160697\n",
            "Recall %: 76.04909070160697\n",
            "----------------\n",
            "SVC()\n",
            "Accuracy %: 76.70629610033924\n",
            "Precision %: 76.70629610033924\n",
            "Recall %: 76.70629610033924\n",
            "----------------\n",
            "DecisionTreeClassifier()\n",
            "Accuracy %: 77.3655763385308\n",
            "Precision %: 77.3655763385308\n",
            "Recall %: 77.3655763385308\n",
            "----------------\n",
            "RandomForestClassifier()\n",
            "Accuracy %: 80.7854304773168\n",
            "Precision %: 80.7854304773168\n",
            "Recall %: 80.7854304773168\n",
            "----------------\n",
            "AdaBoostClassifier()\n",
            "Accuracy %: 77.2327866131358\n",
            "Precision %: 77.2327866131358\n",
            "Recall %: 77.2327866131358\n",
            "----------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the grid of parameters to search\n",
        "param_grid = {\n",
        "    'n_estimators': [25, 50, 100, 150, 200],  # Number of trees in the forest\n",
        "    'max_depth': [None, 10, 15, 20, 30, 35],  # Maximum depth of the tree\n",
        "    'min_samples_split': [2, 5, 7, 10],  # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': [1, 2, 4, 8]  # Minimum number of samples required to be at a leaf node\n",
        "}\n",
        "\n",
        "# Perform grid search with cross-validation for the model with best scores\n",
        "grid_search = GridSearchCV(estimator=forest, param_grid=param_grid, cv=5)\n",
        "grid_search.fit(x_train, y_train)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best parameters found:\")\n",
        "print(grid_search.best_params_)\n",
        "\n",
        "# Print the best mean cross-validated score found\n",
        "print(\"Best mean cross-validated score found:\")\n",
        "print(grid_search.best_score_)\n"
      ],
      "metadata": {
        "id": "RM2FkvlghFKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the fine tuned model\n",
        "forest=RandomForestClassifier(max_depth=None,min_samples_leaf=1,min_samples_split=5,n_estimators=50)\n",
        "forest.fit(x_train,y_train)"
      ],
      "metadata": {
        "id": "QC6Sk111e20I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "y_hat=forest.predict(x_test)\n",
        "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
        "print(\"accuracy% :\",accuracy_score(y_hat,y_test)*100)\n",
        "print(\"precision% :\",precision_score(y_hat,y_test)*100)\n",
        "print(\"recall% :\",recall_score(y_hat,y_test)*100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "drzovbNfe23d",
        "outputId": "7a09e2fe-4c7f-4811-a8bd-82fd36efb02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy% : 82.63157894736842\n",
            "precision% : 88.17204301075269\n",
            "recall% : 78.84615384615384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install gradio\n",
        "!pip install gradio==3.14.0"
      ],
      "metadata": {
        "id": "2cnxUF2bozQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build a function for predictions\n",
        "def predict_output(features):\n",
        "    # Convert the list of features to a numpy array\n",
        "    features_array = np.array(features).reshape(1, -1)\n",
        "    # Use the pre-trained model to predict\n",
        "    prediction = forest.predict(features_array)[0]\n",
        "    return prediction\n",
        "# Test the function\n",
        "predict_output(data.iloc[1,:8].values)"
      ],
      "metadata": {
        "id": "P5CciJrbnQUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the inputs as a list of Number objects\n",
        "inputs = [gr.inputs.Number(default=0, label=f\"Feature {i+1}\") for i in range(8)]\n",
        "\n",
        "# Create the Gradio interface with the predict_output function and the inputs\n",
        "gr.Interface(fn=predict_output, inputs=inputs, outputs=\"number\", title=\"Predict Output\").launch()"
      ],
      "metadata": {
        "id": "o0ldqd2tnQmK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}