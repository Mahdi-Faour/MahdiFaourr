{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZBqX0I0W+iiuaYENjmCTC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MahdiFaourr/MahdiFaourr/blob/main/colon_disease_multiclassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "artSLIWTzM_5"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio==3.14.0"
      ],
      "metadata": {
        "id": "h15-aNaU2Oz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset from kaggle\n",
        "od.download(\"https://www.kaggle.com/datasets/francismon/curated-colon-dataset-for-deep-learning\")"
      ],
      "metadata": {
        "id": "FCCts3skzZx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries and functions\n",
        "import opendatasets as od\n",
        "from tensorflow.keras.metrics import Precision\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.mobilenet import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.layers import MaxPooling2D,Dense,Flatten,Conv2D,Input,GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import gradio as gr\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ami_bXnZoomR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up data generators with augmentation options\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "train_generator =datagen.flow_from_directory(\"/content/curated-colon-dataset-for-deep-learning/train\"\n",
        "    ,\n",
        "    target_size=(224, 224),  # Adjust target size as needed\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "validation_generator =datagen.flow_from_directory(\"/content/curated-colon-dataset-for-deep-learning/val\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "test_generator =datagen.flow_from_directory(\"/content/curated-colon-dataset-for-deep-learning/test\",\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ],
      "metadata": {
        "id": "YUvRYMlDzZ0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load MobileNetV1 base model without top (fully connected) layers\n",
        "#base_model = MobileNet(weights='imagenet', include_top=False)\n",
        "base_model = MobileNet(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the MobileNetV1 base model to the Sequential model\n",
        "model.add(base_model)\n",
        "# Set MobileNetV1 layers as non-trainable\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Add GlobalAveragePooling2D layer to reduce spatial dimensions\n",
        "model.add(GlobalAveragePooling2D())\n",
        "\n",
        "# Add custom dense layers for classification\n",
        "model.add(Dense(220, activation='relu'))\n",
        "model.add(Dense(4, activation='softmax'))"
      ],
      "metadata": {
        "id": "bsRP81iIzZ-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy',Precision()])\n",
        "# Define a checkpoint callback to save the best\n",
        "checkpoint = ModelCheckpoint('best_weights.h5', monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)\n",
        "# Train the model\n",
        "history=model.fit(train_generator,validation_data=(validation_generator),epochs=10,batch_size=len(train_generator),callbacks=[checkpoint])"
      ],
      "metadata": {
        "id": "OckxfG7Ln1sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best weights into your model\n",
        "model.load_weights('best_weights.h5')"
      ],
      "metadata": {
        "id": "gXGLLN60n1vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test_generator\n",
        "model.evaluate(test_generator)"
      ],
      "metadata": {
        "id": "hrvCoG9Yn1x-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16d6d0c3-af80-4fbd-eeea-def4c923ea81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 [==============================] - 27s 1s/step - loss: 0.1942 - accuracy: 0.9200 - precision: 0.9256\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.19419117271900177, 0.9200000166893005, 0.9255989789962769]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model as HDF5 file\n",
        "model.save(\"colon_model.h5\")"
      ],
      "metadata": {
        "id": "yDJJsVc4n10l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# `history.history` is a dictionary containing the training and validation metrics\n",
        "# Plotting accuracy\n",
        "plt.subplot(2, 1, 1)  # 2 rows, 1 column, plot 1 (top subplot)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "# Plotting precision\n",
        "plt.subplot(2, 1, 2)  # 2 rows, 1 column, plot 2 (bottom subplot)\n",
        "plt.plot(history.history['precision'])\n",
        "plt.plot(history.history['val_precision'])\n",
        "plt.title('Model Precision')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Precision')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "\n",
        "plt.tight_layout()  # Adjust subplot layout to avoid overlap\n",
        "\n",
        "# Show plot\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cIyT_v7bn16H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def diagnosis(img_path):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.open(img_path)\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = np.argmax(model.predict(img_array))\n",
        "    if prediction==0:\n",
        "        return 'Normal'\n",
        "    elif prediction==1:\n",
        "      return \"ulcreative colitis\"\n",
        "    elif prediction==2:\n",
        "      return \"Polyps\"\n",
        "    else:\n",
        "        return 'Esophagitis'\n"
      ],
      "metadata": {
        "id": "K_PO7gsln2BU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 1\n",
        "image_path=\"/content/curated-colon-dataset-for-deep-learning/train/0_normal/train_normal_ (10).jpg\"\n",
        "diagnosis(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "07rvDPZm05Fx",
        "outputId": "4d0312fb-cef0-461e-c89f-88b3b08dd3a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 421ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Normal'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 2\n",
        "image_path=\"/content/curated-colon-dataset-for-deep-learning/val/1_ulcerative_colitis/val_ulcer_ (101).jpg\"\n",
        "diagnosis(image_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "tDJw1kkn05IL",
        "outputId": "a9946e71-8081-4e00-8154-b4049ed74066"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ulcreative colitis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage 3\n",
        "image_path=\"/content/curated-colon-dataset-for-deep-learning/test/3_esophagitis/test_esophagitis_ (100).jpg\"\n",
        "diagnosis(image_path)"
      ],
      "metadata": {
        "id": "s066BGvBzaBE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "01dafe47-64a9-4bac-e1f1-de70cb5d1e2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 65ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Esophagitis'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function suitable for gradio\n",
        "def gradio_fn(img_array):\n",
        "    # Convert the numpy array to a PIL Image object\n",
        "    img = Image.fromarray(np.uint8(img_array))\n",
        "\n",
        "    # Convert grayscale image to RGB\n",
        "    if img.mode != 'RGB':\n",
        "        img = img.convert('RGB')\n",
        "\n",
        "    # Resize the image to match the model's expected input size\n",
        "    img = img.resize((224, 224))\n",
        "\n",
        "    # Normalize the image data\n",
        "    img_array = np.array(img) / 255.0\n",
        "\n",
        "    # Expand the dimensions to match the model's expected input shape\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = model.predict(img_array)\n",
        "\n",
        "    # Use the model to predict\n",
        "    prediction = np.argmax(model.predict(img_array))\n",
        "    if prediction==0:\n",
        "        return 'Normal'\n",
        "    elif prediction==1:\n",
        "      return \"ulcreative colitis\"\n",
        "    elif prediction==2:\n",
        "      return \"Polyps\"\n",
        "    else:\n",
        "        return 'Esophagitis'"
      ],
      "metadata": {
        "id": "CXL0ApaF3yau"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input component for the Gradio interface\n",
        "inputs = gr.inputs.Image(shape=(224, 224))\n",
        "\n",
        "# Define the output component for the Gradio interface\n",
        "outputs = gr.outputs.Label()\n",
        "\n",
        "# Create the Gradio interface\n",
        "gr.Interface(gradio_fn, inputs, outputs, capture_session=True,share=True).launch(debug='True')"
      ],
      "metadata": {
        "id": "D3lOu02R3NKm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}